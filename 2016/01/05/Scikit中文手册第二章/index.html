<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <link rel="icon" type="image/x-icon" href="/favicon.ico">
  
  <title>Scikit中文手册第二章 | 不如</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="简介线性模型是统计学和机器学习的基础。许多方法依赖线性模型描述了数据的关联。我们会做很多的努力把模型转化成线性模型。在这一章，我们建立最朴素的思想用来分类，和贝叶斯的岭回归。
拟合直线现在我们开始建模，我们从最简单的线性回归开始，所以我们使用最基本的模型，一条直线。
准备波士顿数据集很适合回归。波士顿地区的平均房价与许多因素有关，例如犯罪率。
from sklearn import dataset">
<meta property="og:type" content="article">
<meta property="og:title" content="Scikit中文手册第二章">
<meta property="og:url" content="http://yoursite.com/2016/01/05/Scikit中文手册第二章/index.html">
<meta property="og:site_name" content="不如">
<meta property="og:description" content="简介线性模型是统计学和机器学习的基础。许多方法依赖线性模型描述了数据的关联。我们会做很多的努力把模型转化成线性模型。在这一章，我们建立最朴素的思想用来分类，和贝叶斯的岭回归。
拟合直线现在我们开始建模，我们从最简单的线性回归开始，所以我们使用最基本的模型，一条直线。
准备波士顿数据集很适合回归。波士顿地区的平均房价与许多因素有关，例如犯罪率。
from sklearn import dataset">
<meta property="og:updated_time" content="2016-01-07T16:39:59.886Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Scikit中文手册第二章">
<meta name="twitter:description" content="简介线性模型是统计学和机器学习的基础。许多方法依赖线性模型描述了数据的关联。我们会做很多的努力把模型转化成线性模型。在这一章，我们建立最朴素的思想用来分类，和贝叶斯的岭回归。
拟合直线现在我们开始建模，我们从最简单的线性回归开始，所以我们使用最基本的模型，一条直线。
准备波士顿数据集很适合回归。波士顿地区的平均房价与许多因素有关，例如犯罪率。
from sklearn import dataset">
  
    <link rel="alternative" href="/atom.xml" title="不如" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="/img/pp.png" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">刘思亮</a></h1>
		</hgroup>

		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/Heipiao" title="github">github</a>
					        
								<a class="weibo" target="_blank" href="/#" title="weibo">weibo</a>
					        
								<a class="rss" target="_blank" href="/#" title="rss">rss</a>
					        
								<a class="zhihu" target="_blank" href="/#" title="zhihu">zhihu</a>
					        
								<a class="linkedin" target="_blank" href="/#" title="linkedin">linkedin</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/ML/" style="font-size: 16.67px;">ML</a> <a href="/tags/data/" style="font-size: 10px;">data</a> <a href="/tags/pip/" style="font-size: 10px;">pip</a> <a href="/tags/python/" style="font-size: 20px;">python</a> <a href="/tags/scikit/" style="font-size: 13.33px;">scikit</a> <a href="/tags/scikit-learn/" style="font-size: 10px;">scikit-learn</a> <a href="/tags/xgboost/" style="font-size: 10px;">xgboost</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">开始写程序~</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">刘思亮</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img lazy-src="/img/pp.png" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author">刘思亮</h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/Heipiao" title="github">github</a>
			        
						<a class="weibo" target="_blank" href="/#" title="weibo">weibo</a>
			        
						<a class="rss" target="_blank" href="/#" title="rss">rss</a>
			        
						<a class="zhihu" target="_blank" href="/#" title="zhihu">zhihu</a>
			        
						<a class="linkedin" target="_blank" href="/#" title="linkedin">linkedin</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap"><article id="post-Scikit中文手册第二章" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/01/05/Scikit中文手册第二章/" class="article-date">
  	<time datetime="2016-01-05T13:33:16.000Z" itemprop="datePublished">2016-01-05</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Scikit中文手册第二章
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
        

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="简介">简介</h1><p>线性模型是统计学和机器学习的基础。许多方法依赖线性模型描述了数据的关联。我们会做很多的努力把模型转化成线性模型。<br>在这一章，我们建立最朴素的思想用来分类，和贝叶斯的岭回归。</p>
<h1 id="拟合直线">拟合直线</h1><p>现在我们开始建模，我们从最简单的线性回归开始，所以我们使用最基本的模型，一条直线。</p>
<h2 id="准备">准备</h2><p>波士顿数据集很适合回归。波士顿地区的平均房价与许多因素有关，例如犯罪率。</p>
<pre><code>from sklearn import datasets
boston = datasets.<span class="function"><span class="title">load_boston</span><span class="params">()</span></span>
</code></pre><h2 id="怎样去做">怎样去做</h2><p>实际上，使用线性模型十分简单。直接使用API，就和前面的章节一样。<br>首先使用LinearRegression对象。</p>
<pre><code>from sklearn<span class="class">.linear_model</span> import LinearRe
lr = <span class="function"><span class="title">LinearRegression</span><span class="params">()</span></span>
lr.<span class="function"><span class="title">fit</span><span class="params">(boston.data, boston.target)</span></span>

predictions = lr.<span class="function"><span class="title">predict</span><span class="params">(boston.data)</span></span>
</code></pre><p>我们来看看预测值和实际值的差值。我们使用一个直方图来看看不同。<br>接下来，回到数据我们要看见消极的影响，也可以看见积极的影响。</p>
<h2 id="更多">更多</h2><h1 id="解析线性模型">解析线性模型</h1><p>这一节。我们看看怎样更好的拟合数据。我们拟合一组数据，然后关注我们如何更好的拟合它。</p>
<h2 id="准备-1">准备</h2><p>我们仍然使用上一节的lr对象和boston数据集，lr有很多有用的方法。</p>
<h2 id="怎样去做-1">怎样去做</h2><p>这里有一些十分简单的指标，我们来看看上一节的残值分析。<br>    import matplotlib.pyplot as plt<br>    import numpy as np<br>    f = plt.figure(figsize=(7, 5))<br>    ax = f.add_subplot(111)<br>    ax.hist(boston.target - predictions, bins=50)<br>    ax.set_title(“Histogram of Residuals.”)<br>正如我之前提到的，错误的值的均值应该为0.这个残值就是错误。我们应该看看平均值，它应该很接近0.</p>
<pre><code>np.<span class="function"><span class="title">mean</span><span class="params">(boston.target - predictions)</span></span>
</code></pre><p>我们还可以使用Scipy来画图。<br>我们还可以看看，其他的指标。平方错误（MSE）和绝对偏差（MAD）。</p>
<pre><code><span class="function"><span class="keyword">def</span> <span class="title">MSE</span><span class="params">(target, predictions)</span>:</span>
    squared_deviation = np.power(target - predictions, <span class="number">2</span>)
    <span class="keyword">return</span> np.mean(squared_deviation)

<span class="function"><span class="keyword">def</span> <span class="title">MAD</span><span class="params">(target, predictions)</span>:</span>
    absolute_deviation = np.abs(target - predictions)
    <span class="keyword">return</span> np.mean(absolute_deviation)
</code></pre><h2 id="怎样工作">怎样工作</h2><p>这是MSE：E(y1-y2）^2 它很简单就是求了，预测值和正确值差的平方。<br>这是MAD：E|y1-y2| </p>
<h2 id="更多-1">更多</h2><p>自举是一种普遍的方法来检测不确定性。</p>
<pre><code>n_bootstraps = <span class="number">1000</span>
len_boston = <span class="function"><span class="title">len</span><span class="params">(boston.target)</span></span>
subsample_size = np.<span class="function"><span class="title">int</span><span class="params">(<span class="number">0.5</span>*len_boston)</span></span>

subsample = lambda: np<span class="class">.random</span><span class="class">.choice</span>(np.<span class="function"><span class="title">arange</span><span class="params">(<span class="number">0</span>, len_boston)</span><span class="title">size</span></span>=subsample_size)
coefs = np.<span class="function"><span class="title">ones</span><span class="params">(n_bootstraps)</span></span> <span class="id">#pre-allocate</span> the space <span class="keyword">for</span> the coefs
<span class="keyword">for</span> <span class="tag">i</span> <span class="keyword">in</span> <span class="function"><span class="title">range</span><span class="params">(n_bootstraps)</span></span>:
    subsample_idx = <span class="function"><span class="title">subsample</span><span class="params">()</span></span>
    subsample_X = boston<span class="class">.data</span>[subsample_idx]
    subsample_y = boston<span class="class">.target</span>[subsample_idx]
lr.<span class="function"><span class="title">fit</span><span class="params">(subsample_X, subsample_y)</span></span>
coefs[i] = lr<span class="class">.coef_</span>[<span class="number">0</span>]

import matplotlib<span class="class">.pyplot</span> as plt
f = plt.<span class="function"><span class="title">figure</span><span class="params">(figsize=(<span class="number">7</span>, <span class="number">5</span>)</span></span>)
ax = f.<span class="function"><span class="title">add_subplot</span><span class="params">(<span class="number">111</span>)</span></span>
ax.<span class="function"><span class="title">hist</span><span class="params">(coefs, bins=<span class="number">50</span>)</span></span>
ax.<span class="function"><span class="title">set_title</span><span class="params">(<span class="string">"Histogram of the lr.coef_[0]."</span>)</span></span>
</code></pre><h1 id="使用岭回归去克服线性回归的短处">使用岭回归去克服线性回归的短处</h1><p>这一节我们学习岭回归。不同于常规回归，这介绍了常规的参数。</p>
<h2 id="准备-2">准备</h2><p>我们使用数据集效率十分的低，这个我们要求矩阵是满秩。</p>
<h2 id="怎样去做-2">怎样去做</h2><p>我们创造一个有效阶为2的矩阵。<br>    from sklearn.datasets import make_regression<br>    reg_data, reg_target = make_regression(n_samples=2000,<br>    n_features=3, effective_rank=2, noise=10)<br>    First, let’s take a look at regular linear regression:<br>    import numpy as np<br>    n_bootstraps = 1000<br>    len_data = len(reg_data)<br>    subsample_size = np.int(0.75*len_data)<br>    subsample = lambda: np.random.choice(np.arange(0, len_data),<br>    size=subsample_size)</p>
<h1 id="优化岭回归的参数">优化岭回归的参数</h1><p>一旦你开始使用岭回归去预测，你建立的模型的参数。你可以考虑参数alpha的值。<br>例如，使用最小二乘法也可以，展示两个变量之间的关系。然而，这时需要做一个决策。</p>
<h2 id="准备-3">准备</h2><p>我们使用交叉验证的方法来处理岭回归。如果你还记得，在岭回归我们创造回归数据集。</p>
<pre><code>from sklearn.datasets import make_regression
reg_data, reg_target = make_regression(n_samples=<span class="number">100</span>,
n_features=<span class="number">2</span>, effective_rank=<span class="number">1</span>, noise=<span class="number">10</span>)
</code></pre><h2 id="怎样去做-3">怎样去做</h2><p>在线性模型，这里有个对象是RidgeCV，这里就可以表现出交叉验证。</p>
<pre><code>from sklearn<span class="class">.linear_model</span> import RidgeCV
rcv = <span class="function"><span class="title">RidgeCV</span><span class="params">(alphas=np.array([.<span class="number">1</span>, .<span class="number">2</span>, .<span class="number">3</span>, .<span class="number">4</span>])</span></span>)
rcv.<span class="function"><span class="title">fit</span><span class="params">(reg_data, reg_target)</span></span>
<span class="function"><span class="title">RidgeCV</span><span class="params">(alphas=array([ <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>])</span></span>, cv=None,
fit_intercept=True, gcv_mode=None, loss_func=None,
normalize=False, score_func=None, scoring=None,
store_cv_values=False)
</code></pre><p>在我们拟合回归之后，我们选择最佳的alpha。</p>
<pre><code>rcv2 = RidgeCV(alphas=np.<span class="built_in">array</span>([<span class="number">.08</span>, <span class="number">.09</span>, <span class="number">.1</span>, <span class="number">.11</span>, <span class="number">.12</span>]))
rcv2.fit(reg_data, reg_target)
RidgeCV(alphas=<span class="built_in">array</span>([ <span class="number">0.08</span>, <span class="number">0.09</span>, <span class="number">0.1</span> , <span class="number">0.11</span>, <span class="number">0.12</span>]), cv=None,
fit_intercept=True, gcv_mode=None,
loss_func=None, normalize=False,
score_func=None, scoring=None,
store_cv_values=False)
</code></pre><p>我们可以进一步这个过程。</p>
<h2 id="怎样工作-1">怎样工作</h2><p>我们来看看，我们是如何定义这个最好的参数。<br><strong>没懂</strong></p>
<h1 id="使用稀疏矩阵来正规化模型">使用稀疏矩阵来正规化模型</h1><p>这里使用lasso算法。<br>。。。。</p>
<h1 id="使用线性模型进行逻辑回归">使用线性模型进行逻辑回归</h1><p>线性模型实际上可以用做分类，他会拟合一个特定的函数，然后指定特定的输出来分类。</p>
<h2 id="准备-4">准备</h2><pre><code>from sklearn<span class="class">.datasets</span> import make_classification
X, y = <span class="function"><span class="title">make_classification</span><span class="params">(n_samples=<span class="number">1000</span>, n_features=<span class="number">4</span>)</span></span>
</code></pre><h2 id="怎样去做-4">怎样去做</h2><p>这个LogisticRegression对象和其他线性模型一样。</p>
<pre><code>from sklearn<span class="class">.linear_model</span> import LogisticRegression
lr = <span class="function"><span class="title">LogisticRegression</span><span class="params">()</span></span>
</code></pre><p>我们只使用最后200来测试，前面来训练模型。</p>
<pre><code><span class="name">X_train</span> = <span class="name">X</span>[:-<span class="number">200</span>]
<span class="name">X_test</span> = <span class="name">X</span>[-<span class="number">200</span>:]
<span class="atom">y_train</span> = <span class="atom">y</span>[:-<span class="number">200</span>]
<span class="atom">y_test</span> = <span class="atom">y</span>[-<span class="number">200</span>:]
</code></pre><p>我们讨论更多的交叉验证在后面的章节。现在我们使用逻辑回归。我们来预测训练集。</p>
<pre><code>lr.<span class="function"><span class="title">fit</span><span class="params">(X_train, y_train)</span></span>
y_train_predictions = lr.<span class="function"><span class="title">predict</span><span class="params">(X_train)</span></span>
y_test_predictions = lr.<span class="function"><span class="title">predict</span><span class="params">(X_test)</span></span>
</code></pre><p>我们现在来看看预测的性能，这个计算也很简单。我们直接计算正确率就好了：</p>
<pre><code>(y_train_predictions == y_train).<span class="function"><span class="title">sum</span><span class="params">()</span></span>.<span class="function"><span class="title">astype</span><span class="params">(float)</span></span> /
y_train<span class="class">.shape</span>[<span class="number">0</span>]
<span class="number">0.8662499</span>
</code></pre><p>使用这个方法同样我们可以用来分类。</p>
<h2 id="更多-2">更多</h2><p>我们创造一个不平衡率为95%的数据集。</p>
<pre><code>X, y = make_classification(n_samples=<span class="number">5000</span>, n_features=<span class="number">4</span>,
weights=[.<span class="number">95</span>])
<span class="function"><span class="title">sum</span><span class="params">(y)</span></span> / (<span class="function"><span class="title">len</span><span class="params">(y)</span></span>*<span class="number">1</span>.) <span class="id">#to</span> confirm the class imbalance
    <span class="number">0.0555</span>
</code></pre><p>我们使用逻辑回归来拟合数据。</p>
<pre><code>X_train = X[:-<span class="number">500</span>]
X_test = X[-<span class="number">500</span>:]
y_train = y[:-<span class="number">500</span>]
y_test = y[-<span class="number">500</span>:]
lr.<span class="function"><span class="title">fit</span><span class="params">(X_train, y_train)</span></span>
y_train_predictions = lr.<span class="function"><span class="title">predict</span><span class="params">(X_train)</span></span>
y_test_predictions = lr.<span class="function"><span class="title">predict</span><span class="params">(X_test)</span></span>
Now, to see how well our model fis the data, do the following:
(y_train_predictions == y_train).<span class="function"><span class="title">sum</span><span class="params">()</span></span>.<span class="function"><span class="title">astype</span><span class="params">(float)</span></span> /
y_train<span class="class">.shape</span>[<span class="number">0</span>]
    <span class="number">0.96977</span>
(y_test_predictions == y_test).<span class="function"><span class="title">sum</span><span class="params">()</span></span>.<span class="function"><span class="title">astype</span><span class="params">(float)</span></span> / y_test<span class="class">.shape</span>[<span class="number">0</span>]
    <span class="number">0.97999</span>
</code></pre><h1 id="直接使用贝叶斯岭回归">直接使用贝叶斯岭回归</h1><p>。。。。</p>
<h1 id="从错误开始增强学习">从错误开始增强学习</h1><p>增强学习回归，他们从一系列弱学习器中，制造出一个强学习器。</p>
<h2 id="准备-5">准备</h2><p>我们使用基本的回归数据，来看看增强学习是如何工作的。</p>
<pre><code>from sklearn<span class="class">.datasets</span> import make_regression
X, y = <span class="function"><span class="title">make_regression</span><span class="params">(<span class="number">1000</span>, <span class="number">2</span>, noise=<span class="number">10</span>)</span></span>
</code></pre><h2 id="怎样去做-5">怎样去做</h2><p>GBR是一个增强学习模块，因为这是一个增强学习器。</p>
<pre><code><span class="keyword">from</span> sklearn.ensemble import GradientBoostingRegressor <span class="keyword">as</span> GBR
gbr = GBR()
gbr.fit(X, y)
gbr_preds = gbr.predict(X)
Clearly, there<span class="comment">'s more to fiting a usable model, but this pattern should be pretty clear by now.</span>
Now, <span class="keyword">let</span><span class="comment">'s fi a basic regression as well so that we can use it as the baseline:</span>
<span class="keyword">from</span> sklearn.linear_model import LinearRegression
lr = LinearRegression()
lr.fit(X, y)
lr_preds = lr.predict(X)
</code></pre><p>我们可以看看增强学习比普通逻辑回归号好多少。</p>
<h2 id="怎样工作-2">怎样工作</h2><p>第一个参数n_estimators就是弱学习器的个数<br>max_depth指树一共有点，<br>loss就是损失函数</p>

      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/01/08/scikit-中文手册-第三章/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          scikit 中文手册 第三章
        
      </div>
    </a>
  
  
    <a href="/2015/12/24/scikit-cookbook-中文翻译/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">scikit cookbook 中文翻译</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>


<div class="share">
	<!-- JiaThis Button BEGIN -->
	<div class="jiathis_style">
		<span class="jiathis_txt">分享到：</span>
		<a class="jiathis_button_tsina"></a>
		<a class="jiathis_button_cqq"></a>
		<a class="jiathis_button_douban"></a>
		<a class="jiathis_button_weixin"></a>
		<a class="jiathis_button_tumblr"></a>
		<a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	</div>
	<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=1405949716054953" charset="utf-8"></script>
	<!-- JiaThis Button END -->
</div>



<div class="duoshuo">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="Scikit中文手册第二章" data-title="Scikit中文手册第二章" data-url="http://yoursite.com/2016/01/05/Scikit中文手册第二章/"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"true"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>




</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2016 刘思亮
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js" type="text/javascript"></script>
<script src="/js/main.js" type="text/javascript"></script>






<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
</body>
</html>